import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import seaborn as sns

from preprocess.preprocess import clean_text


# Custom LDA Topic Extraction
def get_custom_lda_topics(topic_word_matrix, vocabulary, top_n=10):
    """
    Extract topics and top words from custom LDA model output.
    :param topic_word_matrix: A matrix of size [num_topics, vocab_size].
    :param vocabulary: List of vocabulary terms (indexed by columns of topic_word_matrix).
    :param top_n: Number of top words to extract per topic.
    :return: A list of topics with top words.
    """
    topics = []
    for topic_idx, topic in enumerate(topic_word_matrix):
        top_indices = topic.argsort()[-top_n:][::-1]
        top_words = [vocabulary[i] for i in top_indices]
        topics.append((f"Topic {topic_idx + 1}", top_words))
    return topics


def apply_lsa(cleaned_texts, n_components=5):
  """
  Perform Latent Semantic Analysis on text data.
  :param cleaned_texts: List of preprocessed text documents.
  :param n_components: Number of topics/components for LSA.
  :return: LSA topic-word matrix, feature names, and LSA document-topic matrix.
  """
  vectorizer = TfidfVectorizer(
    max_features=5000)  # Convert text to TF-IDF matrix
  tfidf_matrix = vectorizer.fit_transform(cleaned_texts)
  feature_names = vectorizer.get_feature_names_out()

  # Apply SVD
  svd = TruncatedSVD(n_components=n_components, random_state=42)
  document_topic_matrix = svd.fit_transform(tfidf_matrix)
  topic_word_matrix = svd.components_

  return topic_word_matrix, feature_names, document_topic_matrix


# Compare LDA and LSA Topics
def compare_lda_lsa(lda_topic_word_matrix, lsa_topic_word_matrix, lda_vocab,
    lsa_vocab, top_n=10):
  """
  Compare the topics generated by LDA and LSA by analyzing top words.
  :param lda_topic_word_matrix: LDA topic-word matrix.
  :param lsa_topic_word_matrix: LSA topic-word matrix.
  :param lda_vocab: LDA vocabulary.
  :param lsa_vocab: LSA vocabulary.
  :param top_n: Number of top words to analyze per topic.
  """
  print("\nLDA Topics:")
  lda_topics = get_custom_lda_topics(lda_topic_word_matrix, lda_vocab, top_n)
  for topic_name, top_words in lda_topics:
    print(f"{topic_name}: {', '.join(top_words)}")

  print("\nLSA Topics:")
  for i, topic in enumerate(lsa_topic_word_matrix):
    top_indices = topic.argsort()[-top_n:][::-1]
    top_words = [lsa_vocab[i] for i in top_indices]
    print(f"Topic {i + 1}: {', '.join(top_words)}")


# Measure Similarity Between LDA and LSA Topics
def measure_topic_similarity(lda_topic_word_matrix, lsa_topic_word_matrix):
  """
  Compute similarity between LDA and LSA topics using cosine similarity.
  :param lda_topic_word_matrix: LDA topic-word matrix.
  :param lsa_topic_word_matrix: LSA topic-word matrix.
  """
  similarity_matrix = cosine_similarity(lda_topic_word_matrix,
                                        lsa_topic_word_matrix)
  print("\nTopic Similarity Matrix (LDA vs. LSA):")
  print(similarity_matrix)

  # Visualize similarity matrix
  plt.figure(figsize=(8, 6))
  sns.heatmap(similarity_matrix, annot=True, cmap="coolwarm",
              xticklabels=[f"LSA {i + 1}" for i in
                           range(len(lsa_topic_word_matrix))],
              yticklabels=[f"LDA {i + 1}" for i in
                           range(len(lda_topic_word_matrix))])
  plt.title("LDA vs. LSA Topic Similarity")
  plt.xlabel("LSA Topics")
  plt.ylabel("LDA Topics")
  plt.show()


# Main Function
def main():
  # Load your dataset
  file_path = "data/tweets.csv"  # Replace with your file path
  text_column = "text"  # Replace with the column containing text
  df = pd.read_csv(file_path)
  raw_texts = df[text_column]

  # Preprocess the text data
  cleaned_texts = clean_text(raw_texts)

  # Your custom LDA model
  # Example: Replace these with your own LDA outputs
  lda_topic_word_matrix = np.random.rand(5,
                                         1000)  # Replace with actual LDA topic-word matrix
  lda_vocab = [f"word_{i}" for i in
               range(1000)]  # Replace with actual vocabulary

  # Apply LSA
  lsa_topic_word_matrix, lsa_vocab, _ = apply_lsa(cleaned_texts, n_components=5)

  # Compare Topics
  compare_lda_lsa(lda_topic_word_matrix, lsa_topic_word_matrix, lda_vocab,
                  lsa_vocab, top_n=10)

  # Measure Similarity
  measure_topic_similarity(lda_topic_word_matrix, lsa_topic_word_matrix)